import{S as i,i as c,s as l,v as p,w as g,x as u,J as d,p as m,n as f,A as z,P as h,R as w}from"../../chunks/vendor-df4f0e23.js";import{P as b}from"../../chunks/ProjectPage-9a011b7c.js";import{s as n}from"../../chunks/Header-cb7925b5.js";import"../../chunks/InfoSection-95bc1a22.js";function v(t){let a,s;return a=new b({props:{imgs:t[0],desc:t[1],info:j,link:_}}),{c(){p(a.$$.fragment)},l(e){g(a.$$.fragment,e)},m(e,o){u(a,e,o),s=!0},p:d,i(e){s||(m(a.$$.fragment,e),s=!0)},o(e){f(a.$$.fragment,e),s=!1},d(e){z(a,e)}}}let j="2021 \u2022 Web App \u2022 Independent",_="https://omarnema.com/parsons-studio-1/qual/gaze-study-svelte/public/";function k(t,a,s){let e;return h(t,n,r=>s(2,e=r)),w(n,e="How We Gaze",e),[["/assets/gaze/gaze-1.png","/assets/gaze/gaze-2.png","/assets/gaze/gaze-3.png","/assets/gaze/kahlo2.png","/assets/gaze/kahlo1.png"],["How We Gaze is a meta-gallery that shows how individuals gaze at pieces of artwork. The gazes hosted in the gallery are crowd-sourced - individuals are invited to view pieces of artwork, and see their gaze visualized in realtime.","This project was built using the Svelte framework, d3.js for visualization, webgazer.js for eye-tracking, and Firebase for data storage. Observable was used for data exploration."]]}class G extends i{constructor(a){super();c(this,a,k,v,l,{})}}export{G as default};
