import{S as i,i as c,s as l,w as p,x as g,y as u,K as d,q as m,o as f,B as h,Q as z,T as w}from"../../chunks/vendor-e4f9a02f.js";import{P as j}from"../../chunks/ProjectPage-96131905.js";import{s as r}from"../../chunks/Header-cb1332db.js";import"../../chunks/paths-28a87002.js";function v(t){let a,s;return a=new j({props:{imgs:t[0],desc:t[1],info:_,link:b}}),{c(){p(a.$$.fragment)},l(e){g(a.$$.fragment,e)},m(e,o){u(a,e,o),s=!0},p:d,i(e){s||(m(a.$$.fragment,e),s=!0)},o(e){f(a.$$.fragment,e),s=!1},d(e){h(a,e)}}}let _="2021 \u2022 Web App \u2022 Independent",b="https://omarnema.com/parsons-studio-1/qual/gaze-study-svelte/public/";function k(t,a,s){let e;return z(t,r,n=>s(2,e=n)),w(r,e="How We Gaze",e),[["/assets/gaze/gaze-1.png","/assets/gaze/gaze-2.png","/assets/gaze/gaze-3.png","/assets/gaze/kahlo2.png","/assets/gaze/kahlo1.png"],["How We Gaze is a meta-gallery that shows how individuals gaze at pieces of artwork. The gazes hosted in the gallery are crowd-sourced - individuals are invited to view pieces of artwork, and see their gaze visualized in realtime.","This project was built using the Svelte.js as a framework, d3.js for visualization, webgazer.js for eye-tracking, and Firebase for data storage. Observable was used for data exploration."]]}class G extends i{constructor(a){super();c(this,a,k,v,l,{})}}export{G as default};
