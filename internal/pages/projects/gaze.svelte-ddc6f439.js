import{S as i,i as c,s as d,w as p,x as u,y as l,K as m,q as g,o as f,B as h,Y as w,Z as z}from"../../chunks/vendor-0b846e11.js";import{P as j}from"../../chunks/ProjectPage-74b06dd8.js";import{s as n}from"../../chunks/state-5273a6e8.js";import"../../chunks/Header-f3c7a93e.js";import"../../chunks/paths-28a87002.js";import"../../chunks/Carousel-978d16ac.js";function v(t){let a,s;return a=new j({props:{imgs:t[0],desc:t[1],info:_,link:b}}),{c(){p(a.$$.fragment)},l(e){u(a.$$.fragment,e)},m(e,o){l(a,e,o),s=!0},p:m,i(e){s||(g(a.$$.fragment,e),s=!0)},o(e){f(a.$$.fragment,e),s=!1},d(e){h(a,e)}}}let _="2021 \u2022 Web App \u2022 Independent",b="https://omarnema.com/parsons-studio-1/qual/gaze-study-svelte/public/";function k(t,a,s){let e;return w(t,n,r=>s(2,e=r)),z(n,e="How We Gaze",e),[["/assets/gaze/gaze2.png","/assets/gaze/gaze1reaction.png","/assets/gaze/mainDemo.mp4"],["How We Gaze is a meta-gallery that shows how individuals gaze at pieces of artwork. The gazes hosted in the gallery are crowd-sourced - individuals are invited to view pieces of artwork, and see their gaze visualized in realtime.","How We Gaze was selected as a winner for the Pudding Cup 2021, an independent data visualization award.","This project was built using the Svelte.js as a framework, d3.js for visualization, webgazer.js for eye-tracking, and Firebase for data storage. Observable was used for data exploration."]]}class x extends i{constructor(a){super();c(this,a,k,v,d,{})}}export{x as default};
